# Comparison of motion data in regard to the perception of spatiotemporal distances in VR

TODO add our video
## Abstract
Several previous studies on depth perception have focused on the perception of ego-centric distances in extrapersonal space; however, perception in peripersonal space has only been addressed in part, with contradicting results. This paper explores the accuracy of spatiotemporal distance perception during surgical procedure virtual reality (VR). Using surgical motion capture data a user research was conducted to investigate the differences in depth perception of raw motion capture data, average filtered motion capture data, and synthetic data. Participants used a VR headset to view a catheter entering and exiting a transparent plane, and their impressions were examined via questionnaires during and after the study. This study revealed that there was not a significant difference in perception between the three motion capture data types.

## Instructions
Experimenter:
- choose category by looking at the according button and press the X-button on the left controller
- press X-button if participant is ready for experiment
- press Y-button to save the experiment data in a file at the end of the experiment

Participant:
- press A-button when catheter punctures plane to record distance to plane

The application needs to be restarted for each participant. 
The data is saved on the HMD at: `\Quest 2\Internal shared storage\Android\data\com.DefaultCompany.MoCapDemo\files`.


## Unity Project
This project uses Unity 2021.3.3f1. \
The main scene can be found in /Assets/Scenes/Main.

## Installation on Oculus Quest 2
The .apk file can be found [here](https://github.com/LariWa/MoCap-Visualization/releases/tag/final). This file has to be installed on the Oculus Quest 2 (e.g. like [this](https://headjack.io/knowledge-base/how-to-easily-sideload-a-vr-app-to-oculus-quest-2/))
